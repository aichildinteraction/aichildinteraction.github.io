<!DOCTYPE html>
<html>
<title>Language-Based AI Agent Interaction with Children</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Inconsolata">
<style>
body, html {
  height: 100%;
  font-family: "Inconsolata", sans-serif;
}

.bgimg {
  background-position: center;
  background-size: cover;
  background-image: url("ai-child-interaction.png");
  min-height: 50%;
}

.menu {
  display: none;
}

.container {
    display: flex;
    align-items: left;
    justify-content: left;
}

.text {
    font-size: 20px;
    padding-left: 20px;
}

</style>
<body>

<!-- Links (sit on top) -->
<div class="w3-top">
  <div class="w3-row w3-padding w3-black">
    <div class="w3-col s1">
      <a href="/#about" class="w3-button w3-block w3-black">ABSTRACT</a>
    </div>
    <div class="w3-col s1">
      <a href="/#topics" class="w3-button w3-block w3-black">TOPICS</a>
    </div>
    <div class="w3-col s2">
      <a href="/#submission" class="w3-button w3-block w3-black">PAPERS</a>
    </div>
    <div class="w3-col s2">
      <a href="/#schedule" class="w3-button w3-block w3-black">SCHEDULE</a>
    </div>
    <div class="w3-col s2">
      <a href="/#organizers" class="w3-button w3-block w3-black">ORGANIZERS</a>
    </div>
    <div class="w3-col s2">
      <a href="/keynotes.html" class="w3-button w3-block w3-black">KEYNOTES</a>
    </div>
    <div class="w3-col s1">
      <a href="/#contacts" class="w3-button w3-block w3-black">CONTACTS</a>
    </div>  
  </div>
</div>

<!-- Header with image -->
<header class="bgimg w3-display-container" style="filter:grayscale(30%)" id="home">
  <div class="w3-display-bottomleft w3-center w3-padding-large w3-hide-small">
	  <span class="w3-tag">In conjunction with <a href=//sites.google.com/view/iwsds2023/home>IWSDS 2023</a>, Los Angeles</span>
  </div>
  <div class="w3-display-middle w3-center">
    <span class="w3-text-white" style="font-size:30px">Language-Based AI Agent Interaction with Children<br/>@IWSDS'23, Los Angeles, USA - February 21st, 2023</span>
  </div>
</header>

<!-- Add a background color and large text to the whole page -->
<div class="w3-sand w3-grayscale w3-large">

<!-- Keynote talks Container -->
<div class="w3-container" id="keynotes">
  <div class="w3-content" style="max-width:700px">
    <h5 class="w3-center w3-padding-48"><span class="w3-tag w3-wide">KEYNOTE TALKS</span></h5>

      <div class="container">
        <div class="image">
            <img height="175" src=http://khiettruong.space/wp-content/uploads/2016/12/khiet_truong.png>
        </div>

        <div class="text">
            <b> Prof. Khiet P. Truong </b> </br>
            University of Twente,</br> Enschede, Netherlands </br>
            Human Media Interaction Group </br>
            <a href=http://khiettruong.space target="_blank"><img width="30" src="link.png"></a></br>
        </div>
     </div>

     <p>
     <b>Towards spoken conversational interaction technology</b></br>
     In this presentation, I will highlight some of the research we are carrying out at Human Media Interaction, University of Twente. Talking to embodied agents, such as robots or virtual agents, can be beneficial for several reasons, ranging from being able to multitask hands-free, to expressing oneself in a less restricted manner in the context of storytelling or information search. Creating these spoken interactions with embodied agents requires not only automatic speech recognition technology but also knowledge about paralinguistics, conversational interaction, and human-computer interaction as well. I will present several examples of our research in which speech technology and knowledge from speech communication research drive our investigations into spoken interactions with embodied agents.
     <p>

     <b>Biography</b></br>
     Khiet Truong is an associate professor at the Human Media Interaction group at University of Twente and her research interests lie investigating spoken (conversational) interaction in human-human and human-agent communications. In particular, she is interested in paralinguistic aspects that are indicative of speaker characteristics and conversation dynamics among speakers for application domains such as human-robot interaction, multimedia retrieval, and digital health. Currently, she is an Associate Editor for IEEE Transactions on Affective Computing, an Editorial Member of Computer Speech and Language, Area Chair for Interspeech 2023, and General Co-Chair for Interspeech 2025. She has also reviewed and chaired numerous positions for conferences such as Interspeech, ACM ICMI, IEEE ACII, ACM/IEEE HRI and IEEE ICASSP.
     </p>

      <div class="container">
        <div class="image">
            <img width="175" src=https://sail.usc.edu/site_files/pictures/shri.jpg>
        </div>

        <div class="text">
            <b> Prof. Shrikanth S. Narayanan </b> </br>
            University of Southern California,</br> Los Angeles, CA </br>
            Signal Analysis and Interpretation Laboratory </br>
            <a href=https://sail.usc.edu/people/shri.html target="_blank"><img width="30" src="link.png"></a></br>
        </div>
     </div>

    <p> 
    <b>Child-centered Multimodal Machine Intelligence </b></br>
    Converging technological advances in sensing, machine learning and computing offer tremendous opportunities for continuous contextually rich yet unobtrusive multimodal, spatiotemporal characterization of a child’s behavior, communication and interaction, across stages of development. This in turn promises novel possibilities for understanding and supporting various aspects of child-inclusive interaction applications from health and well-being to learning and entertainment. Recent approaches that have leveraged judicious use of both data and knowledge have yielded significant advances in this regard, for example in deriving rich, context-aware information from multimodal biobehavioral signal sources including human speech, language, and videos of behavior as well as physiological information. This talk will focus on some of the advances, opportunities and challenges in gathering such data and creating algorithms for machine processing of such cues in a child centric setting. It will highlight some of our ongoing efforts including drawing examples from the domain of Autism Spectrum Disorder. </p>

    <p>
    <b>Biography</b> </br>
 Shrikanth (Shri) Narayanan is University Professor and Niki &amp C. L. Max Nikias Chair in Engineering at the University of Southern California, where he is Professor of Electrical &amp Computer Engineering, Computer Science, Linguistics, Psychology, Neuroscience, Pediatrics, and Otolaryngology—Head &amp Neck Surgery, Director of the Ming Hsieh Institute and Research Director of the Information Sciences Institute. Prior to USC he was with AT&ampT Bell Labs and AT&ampT Research. His research focuses on human-centered information processing and communication technologies. He is a Guggenheim Fellow, member of the European Academy of Sciences and Arts, and a Fellow of the National Academy of Inventors, the Acoustical Society of America, IEEE, ISCA, the American Association for the Advancement of Science (AAAS), the Association for Psychological Science, the Association for the Advancement of Affective Computing (AAAC) and the American Institute for Medical and Biological Engineering (AIMBE). He is a recipient of several honors including the 2015 Engineers Council’s Distinguished Educator Award, a Mellon award for mentoring excellence, the 2005 and 2009 Best Journal Paper awards from the IEEE Signal Processing Society and serving as its Distinguished Lecturer for 2010-11, a 2018 ISCA CSL Best Journal Paper award, and serving as an ISCA Distinguished Lecturer for 2015-16, Willard R. Zemlin Memorial Lecturer for ASHA in 2017, and the Ten Year Technical Impact Award in 2014 and the Sustained Accomplishment Award in 2020 from ACM ICMI. His research and inventions have led to technology commercialization including through startups he co-founded: Behavioral Signals Technologies focused on the telecommunication services and AI based conversational assistance industry and Lyssn focused on mental health care delivery, treatment and quality assurance. </p>
  </div>
</div>

<!-- End page content -->
</div>

<!-- Footer -->
<!--footer class="w3-center w3-light-grey w3-padding-48 w3-large">
</footer-->

<script>
// Tabbed Menu
function openMenu(evt, menuName) {
  var i, x, tablinks;
  x = document.getElementsByClassName("menu");
  for (i = 0; i < x.length; i++) {
    x[i].style.display = "none";
  }
  tablinks = document.getElementsByClassName("tablink");
  for (i = 0; i < x.length; i++) {
    tablinks[i].className = tablinks[i].className.replace(" w3-dark-grey", "");
  }
  document.getElementById(menuName).style.display = "block";
  evt.currentTarget.firstElementChild.className += " w3-dark-grey";
}
document.getElementById("myLink").click();
</script>

</body>
</html>
